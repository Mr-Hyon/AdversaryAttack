# AdversaryAttack
2019 NJU Software Testing and Quality Project

# About this project
This is a course assignment of Software Testing and Quality.<br>
Content: Given a fashion MNIST dataset, there is a model based on TensorFlow which can recognize each picture and its label â€“ for example, there is a picture showing a T-shirt and the model can recognize the picture as a T-shirt by outputting a label number of the tag name of T-shirt. Now, our target is to attack this model by adding noise to the original picture and try to successfully distract the model, making it unable to output the correct label of the picture.<br>
Be advised, the similarity of processed picture and original picture will be taken into consideration to value the algorithm of the attack, which means you cannot just simply change the entire picture by replacing them or turning it into completely black or white pictures.
